{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import Counter\n",
    "from sklearn import preprocessing\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['004#biGRU_diff.csv',\n",
       " 'dlstm_diff.zip',\n",
       " 'decode_train_neg.csv',\n",
       " 'test2_match.csv',\n",
       " 'test_match.csv',\n",
       " 'decode_train_neg_spe.csv',\n",
       " 'sqli_trian.zip',\n",
       " 'train_match.csv',\n",
       " 'sqli_submit_9878.json',\n",
       " 'sqli_test_1',\n",
       " 'test.csv',\n",
       " 'train.csv',\n",
       " 'test_neg_spe.csv',\n",
       " 'sqli_test_2',\n",
       " 'test_pos.csv',\n",
       " 'sqli_train',\n",
       " 'test_neg_pos.csv',\n",
       " 'dlstm_diff.csv',\n",
       " 'decode_train_neg_pos.csv',\n",
       " 'decode_train_pos.csv',\n",
       " '004#dlstm_diff.csv',\n",
       " 'test2.csv',\n",
       " 'sqli_test_2.zip',\n",
       " 'test_neg.csv',\n",
       " 'sqli_test_1-.zip',\n",
       " '007#bi-GRU-MaxPool.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"./data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm_cell <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7f651ce21080>\n",
      "outputs Tensor(\"LSTM/rnn/transpose:0\", shape=(?, 300, 1), dtype=float32)\n",
      "xw_plus_b: Tensor(\"softmax/xw_plus_b:0\", shape=(?, 2), dtype=float32)\n",
      "logits: Tensor(\"softmax/Reshape_1:0\", shape=(?, 300, 2), dtype=float32)\n",
      "logits_softmax: Tensor(\"softmax/Reshape_3:0\", shape=(?, 300, 2), dtype=float32)\n",
      "pred Tensor(\"output/Gather:0\", shape=(?, 2), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/renxinzhang/.conda/envs/tf-gpu-1.3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:95: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "training_steps = 500\n",
    "batch_size = 100\n",
    "display_step = 50\n",
    "\n",
    "# Network Parameters\n",
    "seq_max_len = 300 # Sequence max length\n",
    "vocab_len = 69\n",
    "n_hidden = 1 # hidden layer num of features\n",
    "n_classes = 2 # linear sequence or not\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, seq_max_len, vocab_len])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "# A placeholder for indicating each sequence length\n",
    "seqlen = tf.placeholder(tf.int32, [None,])\n",
    "\n",
    "# # Define weights\n",
    "# weights = {\n",
    "#     'out': tf.Variable(tf.random_normal([100, n_classes], seed=2018))\n",
    "# }\n",
    "# biases = {\n",
    "#     'out': tf.Variable(tf.random_normal([n_classes], seed=2018))\n",
    "# }\n",
    "\n",
    "\n",
    "\n",
    "# Get lstm cell output, providing 'sequence_length' will perform dynamic calculation.\n",
    "with tf.variable_scope(\"LSTM\") as scope:\n",
    "    # Define a lstm cell with tensorflow\n",
    "    lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden, state_is_tuple=True)\n",
    "    print(\"lstm_cell\", lstm_cell)\n",
    "#     init_state = lstm_cell.zero_state(batch_size, dtype=tf.float32)\n",
    "#     print(\"init_state\", lstm_cell)\n",
    "    outputs, states = tf.nn.dynamic_rnn(lstm_cell, x, dtype=tf.float32)\n",
    "    print(\"outputs\", outputs)\n",
    "#     print(\"states\", states)\n",
    "    \n",
    "with tf.variable_scope(\"softmax\"):\n",
    "    softmax_w = tf.get_variable(\"softmax_w\",\n",
    "                                shape=[n_hidden, n_classes],\n",
    "                                initializer=tf.truncated_normal_initializer(stddev=0.05, seed=2018),\n",
    "                                dtype=tf.float32)\n",
    "    softmax_b = tf.get_variable(\"softmax_b\",\n",
    "                                shape=[n_classes],\n",
    "                                initializer=tf.constant_initializer(value=0.),\n",
    "                                dtype=tf.float32)\n",
    "    reshape = tf.reshape(outputs, [-1, n_hidden])\n",
    "    xw_plus_b = tf.nn.xw_plus_b(reshape, softmax_w, softmax_b)\n",
    "    print(\"xw_plus_b:\", xw_plus_b)\n",
    "    logits = tf.reshape(xw_plus_b, [-1, seq_max_len, n_classes])\n",
    "    print(\"logits:\", logits)\n",
    "    logits_softmax = tf.nn.softmax(logits)\n",
    "    print(\"logits_softmax:\", logits_softmax)\n",
    "    \n",
    "with tf.variable_scope(\"output\"):\n",
    "    # Hack to build the indexing and retrieve the right output.\n",
    "    batch_size_ = tf.shape(outputs)[0]\n",
    "    # Start indices for each sample\n",
    "    index = tf.range(0, batch_size_) * seq_max_len + (seqlen - 1)\n",
    "    # Indexing\n",
    "    pred = tf.gather(tf.reshape(logits, [-1, n_classes]), index)\n",
    "    print(\"pred\", pred)\n",
    "\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "#     print(outputs)\n",
    "    # Linear activation, using outputs computed above\n",
    "#     pred = tf.matmul(weights['out'], outputs) + biases['out']\n",
    "\n",
    "    # Define loss and optimizer\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "    \n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "#     optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Evaluate model\n",
    "with tf.name_scope(\"valid\"):\n",
    "    correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lable encoder vocab\n",
      "[' ' '!' '\"' '#' '$' '%' '&' \"'\" '(' ')' '*' '+' ',' '-' '.' '/' '0' '1'\n",
      " '2' '3' '4' '5' '6' '7' '8' '9' ':' ';' '<' '=' '>' '?' '@' '[' '\\\\' ']'\n",
      " '^' '_' '`' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'l' 'm' 'n' 'o'\n",
      " 'p' 'q' 'r' 's' 't' 'u' 'v' 'w' 'x' 'y' 'z' '{' '|' '}' '~']\n"
     ]
    }
   ],
   "source": [
    "vocab = [v for v in ' !\"#$%&\\'()*+,-./0123456789:;<=>?@[\\\\]^_`abcdefghijklmnopqrstuvwxyz{|}~']\n",
    "print(\"lable encoder vocab\")\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "label_encoder.fit(vocab)\n",
    "print(label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_neg():\n",
    "    train_pd = pd.read_csv(\"./data/test_neg.csv\")\n",
    "    train_pd = train_pd.dropna()\n",
    "    max_seq = 300\n",
    "\n",
    "    print(\"get word_list & label encoder\")\n",
    "    word_list = []\n",
    "    for line in tqdm(train_pd.value):\n",
    "        word_list.append([w for w in line][:max_seq])\n",
    "    word_labelencoder = [list(label_encoder.transform(w)) for w in word_list]\n",
    "    del word_list\n",
    "\n",
    "    print(\"padding & one-hot x data\")\n",
    "    x_batch_pad = []\n",
    "    for x in tqdm(word_labelencoder[:]):\n",
    "        list_test = [0] * max_seq\n",
    "        list_test[:len(x)] = x\n",
    "        x_batch_pad.append(list_test)\n",
    "    x_batch_pad = [np.eye(len(vocab))[item] for item in x_batch_pad]\n",
    "    x_batch_size = [len(i) for i in word_labelencoder]\n",
    "    del word_labelencoder\n",
    "\n",
    "    print(\"padding & one-hot y data\")\n",
    "    y_batch = [0] * len(x_batch_pad)\n",
    "    y_batch_pad = [np.eye(2)[item] for item in y_batch]\n",
    "    y_batch_pad = [list(i) for i in y_batch_pad]\n",
    "    return x_batch_pad, x_batch_size, y_batch_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_neg_pos():\n",
    "    train_pd = pd.read_csv(\"./data/test_neg_pos.csv\")\n",
    "    train_pd = train_pd.dropna()\n",
    "    max_seq = 300\n",
    "\n",
    "    print(\"get word_list & label encoder\")\n",
    "    word_list = []\n",
    "    for line in tqdm(train_pd.value):\n",
    "        word_list.append([w for w in line][:max_seq])\n",
    "    word_labelencoder = [list(label_encoder.transform(w)) for w in word_list]\n",
    "    del word_list\n",
    "\n",
    "    print(\"padding & one-hot x data\")\n",
    "    x_batch_pad = []\n",
    "    for x in tqdm(word_labelencoder[:]):\n",
    "        list_test = [0] * max_seq\n",
    "        list_test[:len(x)] = x\n",
    "        x_batch_pad.append(list_test)\n",
    "    x_batch_pad = [np.eye(len(vocab))[item] for item in x_batch_pad]\n",
    "    x_batch_size = [len(i) for i in word_labelencoder]\n",
    "    del word_labelencoder\n",
    "\n",
    "    print(\"padding & one-hot y data\")\n",
    "    y_batch = [0] * len(x_batch_pad)\n",
    "    y_batch_pad = [np.eye(2)[item] for item in y_batch]\n",
    "    y_batch_pad = [list(i) for i in y_batch_pad]\n",
    "    return x_batch_pad, x_batch_size, y_batch_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_neg_sep():\n",
    "    train_pd = pd.read_csv(\"./data/test_neg_spe.csv\")\n",
    "    train_pd = train_pd.dropna()\n",
    "    max_seq = 300\n",
    "\n",
    "    print(\"get word_list & label encoder\")\n",
    "    word_list = []\n",
    "    for line in tqdm(train_pd.value):\n",
    "        word_list.append([w for w in line][:max_seq])\n",
    "    word_labelencoder = [list(label_encoder.transform(w)) for w in word_list]\n",
    "    del word_list\n",
    "\n",
    "    print(\"padding & one-hot x data\")\n",
    "    x_batch_pad = []\n",
    "    for x in tqdm(word_labelencoder[:]):\n",
    "        list_test = [0] * max_seq\n",
    "        list_test[:len(x)] = x\n",
    "        x_batch_pad.append(list_test)\n",
    "    x_batch_pad = [np.eye(len(vocab))[item] for item in x_batch_pad]\n",
    "    x_batch_size = [len(i) for i in word_labelencoder]\n",
    "    del word_labelencoder\n",
    "\n",
    "    print(\"padding & one-hot y data\")\n",
    "    y_batch = [0] * len(x_batch_pad)\n",
    "    y_batch_pad = [np.eye(2)[item] for item in y_batch]\n",
    "    y_batch_pad = [list(i) for i in y_batch_pad]\n",
    "    return x_batch_pad, x_batch_size, y_batch_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_pos():\n",
    "    train_pd = pd.read_csv(\"./data/test_pos.csv\")\n",
    "    max_seq = 300\n",
    "\n",
    "    print(\"get word_list & label encoder\")\n",
    "    word_list = []\n",
    "    for line in tqdm(train_pd.value):\n",
    "        word_list.append([w for w in line][:max_seq])\n",
    "    word_labelencoder = [list(label_encoder.transform(w)) for w in word_list]\n",
    "    del word_list\n",
    "\n",
    "    print(\"padding & one-hot x data\")\n",
    "    x_batch_pad = []\n",
    "    for x in tqdm(word_labelencoder[:]):\n",
    "        list_test = [0] * max_seq\n",
    "        list_test[:len(x)] = x\n",
    "        x_batch_pad.append(list_test)\n",
    "    x_batch_pad = [np.eye(len(vocab))[item] for item in x_batch_pad]\n",
    "    x_batch_size = [len(i) for i in word_labelencoder]\n",
    "    del word_labelencoder\n",
    "\n",
    "    print(\"padding & one-hot y data\")\n",
    "    y_batch = [1] * len(x_batch_pad)\n",
    "    y_batch_pad = [np.eye(2)[item] for item in y_batch]\n",
    "    y_batch_pad = [list(i) for i in y_batch_pad]\n",
    "#     return x_batch_pad[6000:], x_batch_size[6000:], y_batch_pad[6000:]\n",
    "#     return x_batch_pad[:9969+1], x_batch_size[:9969+1], y_batch_pad[:9969+1]\n",
    "    return x_batch_pad[11:], x_batch_size[11:], y_batch_pad[11:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 75261/275214 [00:00<00:00, 485862.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get word_list & label encoder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 275214/275214 [00:00<00:00, 514014.99it/s]\n",
      "  2%|▏         | 4873/275214 [00:00<00:08, 32593.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padding & one-hot x data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 275214/275214 [00:01<00:00, 190254.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padding & one-hot y data\n",
      "(275214, 300, 69) (275214,) (275214, 2)\n"
     ]
    }
   ],
   "source": [
    "# test_data, test_seqlen, test_label = get_train_pos()\n",
    "test_data, test_seqlen, test_label = get_train_neg()\n",
    "# test_data, test_seqlen, test_label = get_train_neg_pos()\n",
    "# test_data, test_seqlen, test_label = get_train_neg_sep()\n",
    "test_data, test_seqlen, test_label = np.array(test_data), np.array(test_seqlen), np.array(test_label)\n",
    "print(test_data.shape, test_seqlen.shape, test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'user denied your request.'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = np.argmax(test_data[0], axis=1)\n",
    "tmp = [label_encoder.inverse_transform(item) for item in tmp]\n",
    "# tmp = [\"\".join(list(item)).strip() for item in tmp]\n",
    "\"\".join(list(tmp)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-2758\"))) union all select 4432, 4432, 4432, 4432, 4432, 4432, 4432, 4432, 4432, 4432, 4432, 4432, 4432, 4432, 4432, 4432, 4432, 4432, 4432, 4432, 4432, 4432, 4432, 4432, 4432, 4432, 4432, 4432, 4432, 4432, 4432, 4432--  and (((\"qwlp\"=\"qwlp'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'-2758\"))) union all select 4432, 4432, 4432, 4432, 4432, 4432, 4432, 4432, 4432, 4432, 4432, 4432, 4432, 4432, 4432, 4432, 4432, 4432, 4432, 4432, 4432, 4432, 4432, 4432, 4432, 4432, 4432, 4432, 4432, 4432, 4432, 4432--  and (((\"qwlp\"=\"qwlp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)//5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./logs/012_BasicModel++/sqli.ckpt-500\n",
      "\t 0 5000 Testing Accuracy: 1.0\n",
      "\t 5000 10000 Testing Accuracy: 0.9992\n",
      "\t 10000 15000 Testing Accuracy: 0.9998\n",
      "\t 15000 20000 Testing Accuracy: 1.0\n",
      "\t 20000 25000 Testing Accuracy: 1.0\n",
      "\t 25000 30000 Testing Accuracy: 0.9994\n",
      "\t 30000 35000 Testing Accuracy: 0.9994\n",
      "\t 35000 40000 Testing Accuracy: 0.9998\n",
      "\t 40000 45000 Testing Accuracy: 0.9998\n",
      "\t 45000 50000 Testing Accuracy: 0.9998\n",
      "\t 50000 55000 Testing Accuracy: 0.9994\n",
      "\t 55000 60000 Testing Accuracy: 0.9992\n",
      "\t 60000 65000 Testing Accuracy: 0.9988\n",
      "\t 65000 70000 Testing Accuracy: 0.9998\n",
      "\t 70000 75000 Testing Accuracy: 1.0\n",
      "\t 75000 80000 Testing Accuracy: 0.9996\n",
      "\t 80000 85000 Testing Accuracy: 1.0\n",
      "\t 85000 90000 Testing Accuracy: 1.0\n",
      "\t 90000 95000 Testing Accuracy: 0.9998\n",
      "\t 95000 100000 Testing Accuracy: 0.9998\n",
      "\t 100000 105000 Testing Accuracy: 0.9996\n",
      "\t 105000 110000 Testing Accuracy: 0.9988\n",
      "\t 110000 115000 Testing Accuracy: 0.9996\n",
      "\t 115000 120000 Testing Accuracy: 0.9996\n",
      "\t 120000 125000 Testing Accuracy: 0.9996\n",
      "\t 125000 130000 Testing Accuracy: 0.9998\n",
      "\t 130000 135000 Testing Accuracy: 0.9998\n",
      "\t 135000 140000 Testing Accuracy: 0.999\n",
      "\t 140000 145000 Testing Accuracy: 0.9996\n",
      "\t 145000 150000 Testing Accuracy: 0.9994\n",
      "\t 150000 155000 Testing Accuracy: 0.9996\n",
      "\t 155000 160000 Testing Accuracy: 0.9998\n",
      "\t 160000 165000 Testing Accuracy: 0.9998\n",
      "\t 165000 170000 Testing Accuracy: 0.9988\n",
      "\t 170000 175000 Testing Accuracy: 0.9998\n",
      "\t 175000 180000 Testing Accuracy: 0.9994\n",
      "\t 180000 185000 Testing Accuracy: 0.9998\n",
      "\t 185000 190000 Testing Accuracy: 0.9992\n",
      "\t 190000 195000 Testing Accuracy: 0.9998\n",
      "\t 195000 200000 Testing Accuracy: 0.9994\n",
      "\t 200000 205000 Testing Accuracy: 0.9996\n",
      "\t 205000 210000 Testing Accuracy: 0.9994\n",
      "\t 210000 215000 Testing Accuracy: 0.9998\n",
      "\t 215000 220000 Testing Accuracy: 0.9996\n",
      "\t 220000 225000 Testing Accuracy: 0.9996\n",
      "\t 225000 230000 Testing Accuracy: 0.9996\n",
      "\t 230000 235000 Testing Accuracy: 0.9998\n",
      "\t 235000 240000 Testing Accuracy: 0.9996\n",
      "\t 240000 245000 Testing Accuracy: 0.9992\n",
      "\t 245000 250000 Testing Accuracy: 0.9998\n",
      "\t 250000 255000 Testing Accuracy: 0.9992\n",
      "\t 255000 260000 Testing Accuracy: 0.9996\n",
      "\t 260000 265000 Testing Accuracy: 0.9988\n",
      "\t 265000 270000 Testing Accuracy: 0.9994\n",
      "\t 270000 275000 Testing Accuracy: 0.9994\n",
      "\t 275000 280000 Testing Accuracy: 1.0\n",
      "Testing Accuracy: 0.999567331616\n"
     ]
    }
   ],
   "source": [
    "LOG_DIR = \"./logs/012_BasicModel++/\"\n",
    "saver = tf.train.Saver(tf.global_variables(), max_to_keep=15)\n",
    "module_file = tf.train.latest_checkpoint(LOG_DIR)\n",
    "\n",
    "test_pred = ''\n",
    "# Start training\n",
    "config = tf.ConfigProto()  \n",
    "config.gpu_options.allow_growth = True  \n",
    "with tf.Session(config=config) as sess:\n",
    "    \n",
    "    saver.restore(sess, module_file)\n",
    "\n",
    "    for i in range((len(test_data)//5000)+1):\n",
    "#         print(i*5000,(i+1)*5000)\n",
    "        feed_dict_tmp={}\n",
    "        feed_dict_tmp[x] = test_data[i*5000:(i+1)*5000]\n",
    "        feed_dict_tmp[y] = test_label[i*5000:(i+1)*5000]\n",
    "        feed_dict_tmp[seqlen] = test_seqlen[i*5000:(i+1)*5000]\n",
    "        if i == 0:\n",
    "            test_pred, test_acc, test_output = sess.run([pred, accuracy, logits_softmax], feed_dict=feed_dict_tmp)\n",
    "#             print(len(feed_dict_tmp[x]))\n",
    "            print(\"\\t\",i*5000,(i+1)*5000,\"Testing Accuracy:\", test_acc)\n",
    "            test_acc = test_acc * len(feed_dict_tmp[x]) / len(test_data) \n",
    "        else:\n",
    "            test_pred_tmp, test_acc_tmp, test_output_tmp = sess.run([pred, accuracy, logits_softmax], feed_dict=feed_dict_tmp)\n",
    "            test_pred = np.vstack((test_pred, test_pred_tmp))\n",
    "            test_output = np.vstack((test_output, test_output_tmp))\n",
    "            test_acc += test_acc_tmp * len(feed_dict_tmp[x]) / len(test_data) \n",
    "#             print(len(feed_dict_tmp[x]))\n",
    "            print(\"\\t\",i*5000,(i+1)*5000,\"Testing Accuracy:\", test_acc_tmp)\n",
    "            \n",
    "    # Calculate accuracy\n",
    "#     test_data = sqli_batch.test_x\n",
    "#     test_label = sqli_batch.test_y\n",
    "#     test_seqlen = sqli_batch.test_size\n",
    "#     test_pred, test_acc, test_output = sess.run([pred, accuracy, logits_softmax], feed_dict={x: test_data, y: test_label, seqlen: test_seqlen})\n",
    "#     print(\"Testing Accuracy:\", test_acc)\n",
    "    print(\"Testing Accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOG_DIR = \"./logs/012_BasicModel++/\"\n",
    "# saver = tf.train.Saver(tf.global_variables(), max_to_keep=15)\n",
    "# module_file = tf.train.latest_checkpoint(LOG_DIR)\n",
    "\n",
    "# test_pred = ''\n",
    "# # Start training\n",
    "# config = tf.ConfigProto()  \n",
    "# config.gpu_options.allow_growth = True  \n",
    "# with tf.Session(config=config) as sess:\n",
    "    \n",
    "#     saver.restore(sess, module_file)\n",
    "\n",
    "            \n",
    "#     # Calculate accuracy\n",
    "# #     test_data = sqli_batch.test_x\n",
    "# #     test_label = sqli_batch.test_y\n",
    "# #     test_seqlen = sqli_batch.test_size\n",
    "#     test_pred, test_acc, test_output = sess.run([pred, accuracy, logits_softmax], feed_dict={x: test_data, y: test_label, seqlen: test_seqlen})\n",
    "#     print(\"Testing Accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(275214, 2)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff len: 119\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "      <th>plabel</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18,218976,106557;18,218977,106557</td>\n",
       "      <td>0</td>\n",
       "      <td>0.701949</td>\n",
       "      <td>1</td>\n",
       "      <td>5313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13,6688,3160;13,6687,3160;13,6689,3160;13,6688...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.991292</td>\n",
       "      <td>1</td>\n",
       "      <td>6539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>synxxzj1q</td>\n",
       "      <td>0</td>\n",
       "      <td>0.534976</td>\n",
       "      <td>1</td>\n",
       "      <td>8596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0.654371</td>\n",
       "      <td>1</td>\n",
       "      <td>9545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16,53786,25037;16,53787,25037;16,53786,25036;1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.980596</td>\n",
       "      <td>1</td>\n",
       "      <td>11119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>__</td>\n",
       "      <td>0</td>\n",
       "      <td>0.835425</td>\n",
       "      <td>1</td>\n",
       "      <td>28280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>,          .       .   10             .</td>\n",
       "      <td>0</td>\n",
       "      <td>0.991338</td>\n",
       "      <td>1</td>\n",
       "      <td>29000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>~</td>\n",
       "      <td>0</td>\n",
       "      <td>0.764041</td>\n",
       "      <td>1</td>\n",
       "      <td>29132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>lxn3qtndnwu9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.554897</td>\n",
       "      <td>1</td>\n",
       "      <td>30175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0.919709</td>\n",
       "      <td>1</td>\n",
       "      <td>30258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tb1doc1oxxxxxb5xpxxxxxxxxxx</td>\n",
       "      <td>0</td>\n",
       "      <td>0.992367</td>\n",
       "      <td>1</td>\n",
       "      <td>34202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>18,216017,99120;18,216018,99120</td>\n",
       "      <td>0</td>\n",
       "      <td>0.900821</td>\n",
       "      <td>1</td>\n",
       "      <td>37340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0.954331</td>\n",
       "      <td>1</td>\n",
       "      <td>40597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>xxlvjk5xfxxn</td>\n",
       "      <td>0</td>\n",
       "      <td>0.985034</td>\n",
       "      <td>1</td>\n",
       "      <td>47702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1lxqcrx5s4c2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.870514</td>\n",
       "      <td>1</td>\n",
       "      <td>50007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>++</td>\n",
       "      <td>0</td>\n",
       "      <td>0.917463</td>\n",
       "      <td>1</td>\n",
       "      <td>53618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>13,6734,3185;13,6733,3185;13,6735,3185;13,6736...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.990967</td>\n",
       "      <td>1</td>\n",
       "      <td>54756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>,,,,</td>\n",
       "      <td>0</td>\n",
       "      <td>0.988842</td>\n",
       "      <td>1</td>\n",
       "      <td>55474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>xxrlq7yexpws</td>\n",
       "      <td>0</td>\n",
       "      <td>0.943278</td>\n",
       "      <td>1</td>\n",
       "      <td>57543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0.768215</td>\n",
       "      <td>1</td>\n",
       "      <td>57958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>~</td>\n",
       "      <td>0</td>\n",
       "      <td>0.668886</td>\n",
       "      <td>1</td>\n",
       "      <td>58498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0.859246</td>\n",
       "      <td>1</td>\n",
       "      <td>60038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>72567,1,0,0,0,1,1,22</td>\n",
       "      <td>0</td>\n",
       "      <td>0.992363</td>\n",
       "      <td>1</td>\n",
       "      <td>62113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>130,513,651,843,1163,1478,1483,1547,1611,2049,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.985686</td>\n",
       "      <td>1</td>\n",
       "      <td>62706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2lxx8f10q</td>\n",
       "      <td>0</td>\n",
       "      <td>0.659736</td>\n",
       "      <td>1</td>\n",
       "      <td>63383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>0.743893</td>\n",
       "      <td>1</td>\n",
       "      <td>63498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>15,28069,11523;15,28069,11524;15,28069,11526;1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.988549</td>\n",
       "      <td>1</td>\n",
       "      <td>64660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>x</td>\n",
       "      <td>0</td>\n",
       "      <td>0.844319</td>\n",
       "      <td>1</td>\n",
       "      <td>66692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>15,26804,14202;15,26805,14202;15,26804,14203</td>\n",
       "      <td>0</td>\n",
       "      <td>0.985302</td>\n",
       "      <td>1</td>\n",
       "      <td>75786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>9,400,223</td>\n",
       "      <td>0</td>\n",
       "      <td>0.916654</td>\n",
       "      <td>1</td>\n",
       "      <td>75813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>18,218297,111105;18,218299,111109;18,218299,11...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.991601</td>\n",
       "      <td>1</td>\n",
       "      <td>222236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>17,104428,54144;17,104431,54144;17,104429,5414...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.990470</td>\n",
       "      <td>1</td>\n",
       "      <td>222701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>;;;;;;;;cntes;;;xge;;;;;;;;yi;;;aepes;;;;;;;;;...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.986499</td>\n",
       "      <td>1</td>\n",
       "      <td>225016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>17,106343,52186;17,106340,52186;17,106342,5218...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.991281</td>\n",
       "      <td>1</td>\n",
       "      <td>225541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>q__</td>\n",
       "      <td>0</td>\n",
       "      <td>0.718864</td>\n",
       "      <td>1</td>\n",
       "      <td>230686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>14,13910,5887;14,14038,5763;14,14039,5763;14,1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.987889</td>\n",
       "      <td>1</td>\n",
       "      <td>237524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>13,6780,3177;13,6782,3177;13,6781,3177</td>\n",
       "      <td>0</td>\n",
       "      <td>0.991612</td>\n",
       "      <td>1</td>\n",
       "      <td>237872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>15,27463,13350;15,27463,13344;15,27462,13344;1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.984688</td>\n",
       "      <td>1</td>\n",
       "      <td>240509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>73765,1,0,0,0,1,1,22</td>\n",
       "      <td>0</td>\n",
       "      <td>0.992427</td>\n",
       "      <td>1</td>\n",
       "      <td>241147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>xllnryn2xhns</td>\n",
       "      <td>0</td>\n",
       "      <td>0.955879</td>\n",
       "      <td>1</td>\n",
       "      <td>241804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>17,107720,52175;17,107716,52175;17,107719,5217...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.990097</td>\n",
       "      <td>1</td>\n",
       "      <td>243979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>15,26835,12932</td>\n",
       "      <td>0</td>\n",
       "      <td>0.858779</td>\n",
       "      <td>1</td>\n",
       "      <td>246541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>15,26905,13736;15,26902,13736;15,26904,13736;1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.989426</td>\n",
       "      <td>1</td>\n",
       "      <td>250400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>17,109250,53982;17,109250,53990;17,109251,5399...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.987153</td>\n",
       "      <td>1</td>\n",
       "      <td>252761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>xxu9vsc0q</td>\n",
       "      <td>0</td>\n",
       "      <td>0.779646</td>\n",
       "      <td>1</td>\n",
       "      <td>254354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>ss</td>\n",
       "      <td>0</td>\n",
       "      <td>0.625209</td>\n",
       "      <td>1</td>\n",
       "      <td>254691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>17,109883,53471;17,109887,53471;17,109886,5347...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.989898</td>\n",
       "      <td>1</td>\n",
       "      <td>255441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>16,53992,24788;16,53995,24788;16,53993,24788;1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.983577</td>\n",
       "      <td>1</td>\n",
       "      <td>258947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>lxnerza1q</td>\n",
       "      <td>0</td>\n",
       "      <td>0.687713</td>\n",
       "      <td>1</td>\n",
       "      <td>260573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>13,6800,3402</td>\n",
       "      <td>0</td>\n",
       "      <td>0.853177</td>\n",
       "      <td>1</td>\n",
       "      <td>261882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>rs</td>\n",
       "      <td>0</td>\n",
       "      <td>0.539490</td>\n",
       "      <td>1</td>\n",
       "      <td>261912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>q</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538696</td>\n",
       "      <td>1</td>\n",
       "      <td>262637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>15,26761,13475;15,26761,13479;15,26761,13476;1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.990700</td>\n",
       "      <td>1</td>\n",
       "      <td>263096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>15,27478,13361</td>\n",
       "      <td>0</td>\n",
       "      <td>0.767807</td>\n",
       "      <td>1</td>\n",
       "      <td>264423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>10,837,403;10,838,403;10,840,403;10,839,403</td>\n",
       "      <td>0</td>\n",
       "      <td>0.989694</td>\n",
       "      <td>1</td>\n",
       "      <td>268325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>17,106528,54980;17,106528,54984;17,106528,5498...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.986700</td>\n",
       "      <td>1</td>\n",
       "      <td>268975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>+ex+gunpla</td>\n",
       "      <td>0</td>\n",
       "      <td>0.839508</td>\n",
       "      <td>1</td>\n",
       "      <td>269293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>16,51734,26886;16,51734,26887;16,51734,26889;1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.991742</td>\n",
       "      <td>1</td>\n",
       "      <td>270251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>18,194861,95533;18,194861,95526;18,194861,9553...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.986959</td>\n",
       "      <td>1</td>\n",
       "      <td>271077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>10,862,417;10,863,417;10,862,418;10,862,420;10...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.991650</td>\n",
       "      <td>1</td>\n",
       "      <td>272863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 value  label      pred  \\\n",
       "0                    18,218976,106557;18,218977,106557      0  0.701949   \n",
       "1    13,6688,3160;13,6687,3160;13,6689,3160;13,6688...      0  0.991292   \n",
       "2                                            synxxzj1q      0  0.534976   \n",
       "3                                                           0  0.654371   \n",
       "4    16,53786,25037;16,53787,25037;16,53786,25036;1...      0  0.980596   \n",
       "5                                                   __      0  0.835425   \n",
       "6              ,          .       .   10             .      0  0.991338   \n",
       "7                                                    ~      0  0.764041   \n",
       "8                                         lxn3qtndnwu9      0  0.554897   \n",
       "9                                                           0  0.919709   \n",
       "10                         tb1doc1oxxxxxb5xpxxxxxxxxxx      0  0.992367   \n",
       "11                     18,216017,99120;18,216018,99120      0  0.900821   \n",
       "12                                                          0  0.954331   \n",
       "13                                        xxlvjk5xfxxn      0  0.985034   \n",
       "14                                        1lxqcrx5s4c2      0  0.870514   \n",
       "15                                                  ++      0  0.917463   \n",
       "16   13,6734,3185;13,6733,3185;13,6735,3185;13,6736...      0  0.990967   \n",
       "17                                                ,,,,      0  0.988842   \n",
       "18                                        xxrlq7yexpws      0  0.943278   \n",
       "19                                                          0  0.768215   \n",
       "20                                                   ~      0  0.668886   \n",
       "21                                                          0  0.859246   \n",
       "22                                72567,1,0,0,0,1,1,22      0  0.992363   \n",
       "23   130,513,651,843,1163,1478,1483,1547,1611,2049,...      0  0.985686   \n",
       "24                                           2lxx8f10q      0  0.659736   \n",
       "25                                                   a      0  0.743893   \n",
       "26   15,28069,11523;15,28069,11524;15,28069,11526;1...      0  0.988549   \n",
       "27                                                   x      0  0.844319   \n",
       "28        15,26804,14202;15,26805,14202;15,26804,14203      0  0.985302   \n",
       "29                                           9,400,223      0  0.916654   \n",
       "..                                                 ...    ...       ...   \n",
       "89   18,218297,111105;18,218299,111109;18,218299,11...      0  0.991601   \n",
       "90   17,104428,54144;17,104431,54144;17,104429,5414...      0  0.990470   \n",
       "91   ;;;;;;;;cntes;;;xge;;;;;;;;yi;;;aepes;;;;;;;;;...      0  0.986499   \n",
       "92   17,106343,52186;17,106340,52186;17,106342,5218...      0  0.991281   \n",
       "93                                                 q__      0  0.718864   \n",
       "94   14,13910,5887;14,14038,5763;14,14039,5763;14,1...      0  0.987889   \n",
       "95              13,6780,3177;13,6782,3177;13,6781,3177      0  0.991612   \n",
       "96   15,27463,13350;15,27463,13344;15,27462,13344;1...      0  0.984688   \n",
       "97                                73765,1,0,0,0,1,1,22      0  0.992427   \n",
       "98                                        xllnryn2xhns      0  0.955879   \n",
       "99   17,107720,52175;17,107716,52175;17,107719,5217...      0  0.990097   \n",
       "100                                     15,26835,12932      0  0.858779   \n",
       "101  15,26905,13736;15,26902,13736;15,26904,13736;1...      0  0.989426   \n",
       "102  17,109250,53982;17,109250,53990;17,109251,5399...      0  0.987153   \n",
       "103                                          xxu9vsc0q      0  0.779646   \n",
       "104                                                 ss      0  0.625209   \n",
       "105  17,109883,53471;17,109887,53471;17,109886,5347...      0  0.989898   \n",
       "106  16,53992,24788;16,53995,24788;16,53993,24788;1...      0  0.983577   \n",
       "107                                          lxnerza1q      0  0.687713   \n",
       "108                                       13,6800,3402      0  0.853177   \n",
       "109                                                 rs      0  0.539490   \n",
       "110                                                  q      0  0.538696   \n",
       "111  15,26761,13475;15,26761,13479;15,26761,13476;1...      0  0.990700   \n",
       "112                                     15,27478,13361      0  0.767807   \n",
       "113        10,837,403;10,838,403;10,840,403;10,839,403      0  0.989694   \n",
       "114  17,106528,54980;17,106528,54984;17,106528,5498...      0  0.986700   \n",
       "115                                         +ex+gunpla      0  0.839508   \n",
       "116  16,51734,26886;16,51734,26887;16,51734,26889;1...      0  0.991742   \n",
       "117  18,194861,95533;18,194861,95526;18,194861,9553...      0  0.986959   \n",
       "118  10,862,417;10,863,417;10,862,418;10,862,420;10...      0  0.991650   \n",
       "\n",
       "     plabel      id  \n",
       "0         1    5313  \n",
       "1         1    6539  \n",
       "2         1    8596  \n",
       "3         1    9545  \n",
       "4         1   11119  \n",
       "5         1   28280  \n",
       "6         1   29000  \n",
       "7         1   29132  \n",
       "8         1   30175  \n",
       "9         1   30258  \n",
       "10        1   34202  \n",
       "11        1   37340  \n",
       "12        1   40597  \n",
       "13        1   47702  \n",
       "14        1   50007  \n",
       "15        1   53618  \n",
       "16        1   54756  \n",
       "17        1   55474  \n",
       "18        1   57543  \n",
       "19        1   57958  \n",
       "20        1   58498  \n",
       "21        1   60038  \n",
       "22        1   62113  \n",
       "23        1   62706  \n",
       "24        1   63383  \n",
       "25        1   63498  \n",
       "26        1   64660  \n",
       "27        1   66692  \n",
       "28        1   75786  \n",
       "29        1   75813  \n",
       "..      ...     ...  \n",
       "89        1  222236  \n",
       "90        1  222701  \n",
       "91        1  225016  \n",
       "92        1  225541  \n",
       "93        1  230686  \n",
       "94        1  237524  \n",
       "95        1  237872  \n",
       "96        1  240509  \n",
       "97        1  241147  \n",
       "98        1  241804  \n",
       "99        1  243979  \n",
       "100       1  246541  \n",
       "101       1  250400  \n",
       "102       1  252761  \n",
       "103       1  254354  \n",
       "104       1  254691  \n",
       "105       1  255441  \n",
       "106       1  258947  \n",
       "107       1  260573  \n",
       "108       1  261882  \n",
       "109       1  261912  \n",
       "110       1  262637  \n",
       "111       1  263096  \n",
       "112       1  264423  \n",
       "113       1  268325  \n",
       "114       1  268975  \n",
       "115       1  269293  \n",
       "116       1  270251  \n",
       "117       1  271077  \n",
       "118       1  272863  \n",
       "\n",
       "[119 rows x 5 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils.extmath import softmax\n",
    "\n",
    "test_pred_label = np.argmax(test_pred, 1)\n",
    "test_real_label = np.argmax(test_label, 1)\n",
    "test_diff = test_pred_label != test_real_label\n",
    "test_diff_index = np.where(test_diff == True)[0]\n",
    "print(\"diff len:\", len(test_diff_index))\n",
    "\n",
    "# test_data = sqli_batch.test_x\n",
    "# test_label = sqli_batch.test_y\n",
    "# test_seqlen = sqli_batch.test_size\n",
    "\n",
    "diff_x = test_data[test_diff_index]\n",
    "diff_x = np.argmax(diff_x, 2)\n",
    "\n",
    "diff_y = test_label[test_diff_index]\n",
    "diff_y = np.argmax(diff_y, 1)\n",
    "\n",
    "test_pred_softmax = softmax(test_pred)\n",
    "# test_pred_softmax = test_pred\n",
    "pred_y = test_pred_softmax[test_diff_index]\n",
    "pred_y = [item[1] for item in pred_y]\n",
    "pred_class = test_pred_label[test_diff_index]\n",
    "\n",
    "diff_x = [label_encoder.inverse_transform(item) for item in diff_x]\n",
    "diff_value = [\"\".join(list(item)).strip() for item in diff_x]\n",
    "\n",
    "diff_pd = pd.DataFrame(diff_value, columns=['value'])\n",
    "diff_pd['label'] = diff_y\n",
    "diff_pd['pred'] = pred_y\n",
    "diff_pd['plabel'] = pred_class\n",
    "diff_pd['id'] = test_diff_index\n",
    "diff_pd.to_csv(\"./result/12#neg.csv\", index=False)\n",
    "diff_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 69)\n",
      "(300,)\n",
      "263\n"
     ]
    }
   ],
   "source": [
    "show_index = 9950\n",
    "showitem = test_data[show_index]\n",
    "showitem_len = test_seqlen[show_index]\n",
    "print(showitem.shape)\n",
    "showitem = np.argmax(showitem, 1)\n",
    "print(showitem.shape)\n",
    "heatmap_x = [label_encoder.inverse_transform(item) for item in showitem]\n",
    "heatmap_x = heatmap_x[:showitem_len]\n",
    "print(showitem_len)\n",
    "heatmap_y = test_output[show_index][:showitem_len]\n",
    "heatmap_y = [[row[1] for row in heatmap_y]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0184084828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 8)) # set figure size\n",
    "for i in range(1):\n",
    "    plt.plot(heatmap_y[i][:len(heatmap_x)], label=str(i))\n",
    "xticks = range(0,len(heatmap_x))\n",
    "ax.set_xticks(xticks) # major ticks\n",
    "ax.set_xticklabels(heatmap_x)   # labels should be 'unicode'\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
