{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from scipy import sparse\n",
    "from tqdm import tqdm\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get word_list & vocab_list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 30000/30000 [00:00<00:00, 101760.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get vocab\n",
      "['%' '&' '*' '+' '-' '.' '0' '1' '2' '3' '4' '5' '6' '7' '8' '9' '=' 'A'\n",
      " 'B' 'C' 'D' 'E' 'F' 'G' 'H' 'I' 'J' 'K' 'L' 'M' 'N' 'O' 'P' 'Q' 'R' 'S'\n",
      " 'T' 'U' 'V' 'W' 'X' 'Y' 'Z' '_' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j'\n",
      " 'k' 'l' 'm' 'n' 'o' 'p' 'q' 'r' 's' 't' 'u' 'v' 'w' 'x' 'y' 'z']\n",
      "lable encoder vocab\n",
      "['%' '&' '*' '+' '-' '.' '0' '1' '2' '3' '4' '5' '6' '7' '8' '9' '=' 'A'\n",
      " 'B' 'C' 'D' 'E' 'F' 'G' 'H' 'I' 'J' 'K' 'L' 'M' 'N' 'O' 'P' 'Q' 'R' 'S'\n",
      " 'T' 'U' 'V' 'W' 'X' 'Y' 'Z' '_' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j'\n",
      " 'k' 'l' 'm' 'n' 'o' 'p' 'q' 'r' 's' 't' 'u' 'v' 'w' 'x' 'y' 'z']\n",
      "label encoder word_list\n",
      "balanced pos & neg data\n",
      "Counter({0: 27159, 1: 1973})\n",
      "[16990 13224 19547 ..., 21312 24136 25566] (1973,)\n",
      "[11951  9750 29412 ...,  4893  9309 20971] (2027,)\n",
      "[16191  3846 29602 ..., 13505 19548 14360] (4000,)\n",
      "get data\n",
      "(4000,) (4000,) 4000\n",
      "padding & one-hot x data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 4000/4000 [00:00<00:00, 37646.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padding & one-hot y data\n",
      "success\n"
     ]
    }
   ],
   "source": [
    "train_pd = pd.read_csv(\"./data/train.csv\", encoding=\"utf-8\")\n",
    "\n",
    "print(\"get word_list & vocab_list\")\n",
    "word_list = []\n",
    "vocab_list = []\n",
    "for line in tqdm(train_pd.value):\n",
    "    word_list.append([w for w in line])\n",
    "    vocab_list.extend([w for w in line])\n",
    "    \n",
    "print(\"get vocab\")\n",
    "c = Counter(vocab_list)\n",
    "vocab = np.array(list(c.keys()))\n",
    "vocab.sort()\n",
    "print(vocab)\n",
    "\n",
    "print(\"lable encoder vocab\")\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "label_encoder.fit(vocab)\n",
    "print(label_encoder.classes_)\n",
    "# label_encoder.transform(vocab)\n",
    "\n",
    "print(\"label encoder word_list\")\n",
    "word_labelencoder = [list(label_encoder.transform(w)) for w in word_list]\n",
    "word_size = [len(i) for i in word_labelencoder]\n",
    "\n",
    "print(\"balanced pos & neg data\")\n",
    "train_size_pd = pd.DataFrame(word_size, columns=['len'])\n",
    "train_size_pd['label'] = train_pd.label\n",
    "# train_size_pd.describe()\n",
    "train_size_pd = train_size_pd[train_size_pd.len < 500]\n",
    "print(Counter(train_size_pd.label))\n",
    "\n",
    "pos_index = train_size_pd[train_size_pd.label == 1].index.values\n",
    "random.shuffle(pos_index)\n",
    "print(pos_index, pos_index.shape)\n",
    "\n",
    "neg_index = train_size_pd[train_size_pd.label == 0].index.values\n",
    "neg_index = np.random.choice(neg_index, size=4000-1973)\n",
    "print(neg_index, neg_index.shape)\n",
    "\n",
    "balance_train_index = np.append(pos_index,neg_index)\n",
    "random.shuffle(balance_train_index)\n",
    "print(balance_train_index, balance_train_index.shape)\n",
    "\n",
    "print(\"get data\")\n",
    "x_batch = np.array(word_labelencoder.copy())\n",
    "x_batch = x_batch[balance_train_index]\n",
    "y_batch = np.array(train_pd.label.copy())\n",
    "y_batch = y_batch[balance_train_index]\n",
    "x_batch_size = [len(i) for i in x_batch]\n",
    "print(x_batch.shape, y_batch.shape, len(x_batch_size))\n",
    "\n",
    "print(\"padding & one-hot x data\")\n",
    "max_size = np.max(x_batch_size)\n",
    "x_batch_pad = []\n",
    "for x in tqdm(x_batch[:]):\n",
    "    list_test = list()\n",
    "    list_test =([-1] * max_size)\n",
    "    list_test[:len(x)] = x\n",
    "#     list_test = [[i] for i in list_test]\n",
    "    x_batch_pad.append(list_test)\n",
    "x_batch_pad = [np.eye(len(vocab))[item] for item in x_batch_pad]\n",
    "   \n",
    "print(\"padding & one-hot y data\")\n",
    "y_batch_pad = [np.eye(2)[item] for item in y_batch]\n",
    "y_batch_pad = [list(i) for i in y_batch_pad]\n",
    "\n",
    "print(\"success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Batcher():\n",
    "    def __init__(self, x, y, x_batch_size):\n",
    "        self.split_size = int(len(x)*0.8)\n",
    "        self.train_x = x[:self.split_size]\n",
    "        self.train_y = y[:self.split_size]\n",
    "        self.train_size = x_batch_size[:self.split_size]\n",
    "        self.test_x = x[self.split_size:]\n",
    "        self.test_y = y[self.split_size:]\n",
    "        self.test_size = x_batch_size[self.split_size:]\n",
    "        self.start = 0\n",
    "    def next_batch(self, batch_size):\n",
    "        s_index = self.start\n",
    "        e_index = self.start + batch_size\n",
    "        if e_index >= self.split_size:\n",
    "            self.start = 0\n",
    "            s_index = self.start\n",
    "            e_index = self.start + batch_size\n",
    "        self.start = e_index\n",
    "        return self.train_x[s_index:e_index], self.train_y[s_index:e_index], self.train_size[s_index:e_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqli_batch = Batcher(x_batch_pad, y_batch_pad, x_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_data, batch_labels, batch_seqlen = sqli_batch.next_batch(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
       "        ..., \n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  1.]]),\n",
       " array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
       "        ..., \n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  1.]])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0],\n",
       " [0.0, 1.0],\n",
       " [1.0, 0.0],\n",
       " [1.0, 0.0]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[374, 110, 104, 404, 325, 56, 63, 263, 72, 46]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_seqlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:96: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "training_steps = 500\n",
    "batch_size = 100\n",
    "display_step = 50\n",
    "\n",
    "# Network Parameters\n",
    "seq_max_len = max_size # Sequence max length\n",
    "n_hidden = 128 # hidden layer num of features\n",
    "n_classes = 2 # linear sequence or not\n",
    "\n",
    "# trainset = ToySequenceData(n_samples=1000, max_seq_len=seq_max_len)\n",
    "# testset = ToySequenceData(n_samples=500, max_seq_len=seq_max_len)\n",
    "sqli_batch = Batcher(x_batch_pad, y_batch_pad, x_batch_size)\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, seq_max_len, len(vocab)])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "# A placeholder for indicating each sequence length\n",
    "seqlen = tf.placeholder(tf.int32, [None,])\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([2*n_hidden, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "\n",
    "def dynamicRNN(x, seqlen, weights, biases):\n",
    "\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, n_steps, n_input)\n",
    "    # Required shape: 'n_steps' tensors list of shape (batch_size, n_input)\n",
    "    \n",
    "    # Unstack to get a list of 'n_steps' tensors of shape (batch_size, n_input)\n",
    "#     x = tf.unstack(x, seq_max_len, 1)\n",
    "\n",
    "    # Define a lstm cell with tensorflow\n",
    "    encoder_fw = tf.contrib.rnn.GRUCell(n_hidden)\n",
    "    encoder_bw = tf.contrib.rnn.GRUCell(n_hidden)\n",
    "#     encoder_fw = tf.contrib.rnn.DropoutWrapper(encoder_fw, output_keep_prob=self.output_keep_prob)\n",
    "#     encoder_bw = tf.contrib.rnn.DropoutWrapper(encoder_bw, output_keep_prob=self.output_keep_prob)\n",
    "\n",
    "    # Get lstm cell output, providing 'sequence_length' will perform dynamic\n",
    "    # calculation.\n",
    "#     outputs, states = tf.contrib.rnn.static_rnn(lstm_cell, x, dtype=tf.float32,\n",
    "#                                 sequence_length=seqlen)\n",
    "    with tf.variable_scope(\"bi-GRU\") as scope:\n",
    "        ((encoder_fw_output, encoder_bw_output), \n",
    "             (encoder_fw_state, encoder_bw_state)) = (\n",
    "                tf.nn.bidirectional_dynamic_rnn(cell_fw=encoder_fw, \n",
    "                                                cell_bw=encoder_bw, \n",
    "                                                inputs=x,\n",
    "                                                sequence_length=seqlen,\n",
    "                                                dtype=tf.float32)\n",
    "            )\n",
    "\n",
    "        outputs = tf.concat((encoder_fw_output, encoder_bw_output), 2) \n",
    "        #[batch_size, max_time, 2 * encoder_hidden_size]\n",
    "        states = tf.concat((encoder_fw_state, encoder_bw_state), 1)\n",
    "\n",
    "    # When performing dynamic calculation, we must retrieve the last\n",
    "    # dynamically computed output, i.e., if a sequence length is 10, we need\n",
    "    # to retrieve the 10th output.\n",
    "    # However TensorFlow doesn't support advanced indexing yet, so we build\n",
    "    # a custom op that for each sample in batch size, get its length and\n",
    "    # get the corresponding relevant output.\n",
    "\n",
    "    # 'outputs' is a list of output at every timestep, we pack them in a Tensor\n",
    "    # and change back dimension to [batch_size, n_step, n_input]\n",
    "#     outputs = tf.stack(outputs)\n",
    "#     outputs = tf.transpose(outputs, [1, 0, 2])\n",
    "\n",
    "    # Hack to build the indexing and retrieve the right output.\n",
    "    batch_size = tf.shape(outputs)[0]\n",
    "    # Start indices for each sample\n",
    "    index = tf.range(0, batch_size) * seq_max_len + (seqlen - 1)\n",
    "    # Indexing\n",
    "    outputs = tf.gather(tf.reshape(outputs, [-1, 2*n_hidden]), index)\n",
    "\n",
    "    # Linear activation, using outputs computed above\n",
    "    return tf.matmul(outputs, weights['out']) + biases['out']\n",
    "\n",
    "pred = dynamicRNN(x, seqlen, weights, biases)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./biGRU/sqli.ckpt-315\n",
      "Step 100, Minibatch Loss= 0.211029, Training Accuracy= 0.94000\n",
      "Testing Accuracy: 0.96\n",
      "Step 5000, Minibatch Loss= 0.194533, Training Accuracy= 0.93000\n",
      "Testing Accuracy: 0.95625\n",
      "Step 10000, Minibatch Loss= 0.170305, Training Accuracy= 0.96000\n",
      "Testing Accuracy: 0.9625\n",
      "Step 15000, Minibatch Loss= 0.054785, Training Accuracy= 0.99000\n",
      "Testing Accuracy: 0.96\n",
      "Step 20000, Minibatch Loss= 0.115224, Training Accuracy= 0.95000\n",
      "Testing Accuracy: 0.9625\n",
      "Step 25000, Minibatch Loss= 0.146522, Training Accuracy= 0.95000\n",
      "Testing Accuracy: 0.965\n",
      "Step 30000, Minibatch Loss= 0.165512, Training Accuracy= 0.91000\n",
      "Testing Accuracy: 0.95\n",
      "Step 35000, Minibatch Loss= 0.050726, Training Accuracy= 0.99000\n",
      "Testing Accuracy: 0.96375\n",
      "Step 40000, Minibatch Loss= 0.082588, Training Accuracy= 0.98000\n",
      "Testing Accuracy: 0.96875\n",
      "Step 45000, Minibatch Loss= 0.093765, Training Accuracy= 0.97000\n",
      "Testing Accuracy: 0.96625\n",
      "Step 50000, Minibatch Loss= 0.096553, Training Accuracy= 0.97000\n",
      "Testing Accuracy: 0.95625\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.95625\n"
     ]
    }
   ],
   "source": [
    "LOG_DIR = \"./biGRU/\"\n",
    "saver = tf.train.Saver(tf.global_variables(), max_to_keep=15)\n",
    "module_file = tf.train.latest_checkpoint(LOG_DIR)\n",
    "\n",
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "    tf.summary.scalar(\"loss\", cost)\n",
    "    tf.summary.scalar(\"acc\", accuracy)\n",
    "        \n",
    "    merged = tf.summary.merge_all()\n",
    "    train_writer = tf.summary.FileWriter(LOG_DIR + \"train/\", sess.graph)\n",
    "\n",
    "    # Run the initializer\n",
    "#     sess.run(init)\n",
    "    saver.restore(sess, module_file)\n",
    "\n",
    "    for step in range(1, training_steps + 1):\n",
    "        # Get batch data\n",
    "        batch_x, batch_y, batch_seqlen = sqli_batch.next_batch(batch_size)\n",
    "        # Run optimization op (backprop)\n",
    "        summary_ = sess.run(optimizer, feed_dict={x: batch_x, y: batch_y, seqlen: batch_seqlen})\n",
    "#         train_writer.add_summary(summary_, step)\n",
    "        \n",
    "        if step % display_step == 0 or step == 1:\n",
    "            # Calculate batch accuracy & loss\n",
    "            acc, loss = sess.run([accuracy, cost], feed_dict={x: batch_x, y: batch_y,\n",
    "                                                seqlen: batch_seqlen})\n",
    "            print(\"Step \" + str(step*batch_size) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.5f}\".format(acc))\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            test_data = sqli_batch.test_x\n",
    "            test_label = sqli_batch.test_y\n",
    "            test_seqlen = sqli_batch.test_size\n",
    "            test_acc = sess.run(accuracy, feed_dict={x: test_data, y: test_label, seqlen: test_seqlen})\n",
    "            print(\"Testing Accuracy:\", test_acc)\n",
    "        if step % 5 == 0:\n",
    "            saver.save(sess, LOG_DIR+\"sqli.ckpt\", global_step=step)\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Calculate accuracy\n",
    "    test_data = sqli_batch.test_x\n",
    "    test_label = sqli_batch.test_y\n",
    "    test_seqlen = sqli_batch.test_size\n",
    "    test_acc = sess.run(accuracy, feed_dict={x: test_data, y: test_label, seqlen: test_seqlen})\n",
    "    print(\"Testing Accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./biGRU/sqli.ckpt-500\n",
      "Testing Accuracy: 0.95625\n"
     ]
    }
   ],
   "source": [
    "LOG_DIR = \"./biGRU/\"\n",
    "saver = tf.train.Saver(tf.global_variables(), max_to_keep=15)\n",
    "module_file = tf.train.latest_checkpoint(LOG_DIR)\n",
    "\n",
    "test_pred = ''\n",
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    saver.restore(sess, module_file)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    test_data = sqli_batch.test_x\n",
    "    test_label = sqli_batch.test_y\n",
    "    test_seqlen = sqli_batch.test_size\n",
    "    test_pred = sess.run(pred, feed_dict={x: test_data, y: test_label, seqlen: test_seqlen})\n",
    "    print(\"Testing Accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff len: 35\n",
      "get test data\n",
      "get diff raw data\n",
      "test_pred_label [0 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      "test_real_label [1 0 1 1 1 1 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1]\n",
      "    test_data_y [1 0 1 1 1 1 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "test_pred_label = np.argmax(test_pred, 1)\n",
    "test_real_label = np.argmax(test_label, 1)\n",
    "test_diff = test_pred_label != test_real_label\n",
    "test_diff_index = np.where(test_diff == True)[0]\n",
    "print(\"diff len:\", len(test_diff_index))\n",
    "\n",
    "x_batch_lbl = np.array(word_labelencoder.copy())\n",
    "x_batch_lbl = x_batch_lbl[balance_train_index]\n",
    "word_list_array = np.array(word_list)\n",
    "test_data = word_list_array[balance_train_index][int(0.8*len(balance_train_index)):]\n",
    "print(\"get test data\")\n",
    "\n",
    "diff_data = test_data[test_diff_index]\n",
    "diff_data_str = []\n",
    "for data in diff_data:\n",
    "    diff_data_str.append(\"\".join(data))\n",
    "#     print(\"\".join(data))\n",
    "print(\"get diff raw data\")\n",
    "\n",
    "test_data_all = np.array(train_pd.label.copy())\n",
    "test_data_y = test_data_all[balance_train_index][int(0.8*len(balance_train_index)):]\n",
    "\n",
    "print(\"test_pred_label\", test_pred_label[test_diff_index])\n",
    "print(\"test_real_label\", test_real_label[test_diff_index])\n",
    "print(\"    test_data_y\", test_data_y[test_diff_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "diff_pd = pd.DataFrame(diff_data_str, columns=['urldata'])\n",
    "diff_pd['pred'] = test_pred_label[test_diff_index]\n",
    "diff_pd['real'] = test_real_label[test_diff_index]\n",
    "diff_pd['label'] = test_data_y[test_diff_index]\n",
    "diff_pd.to_csv(\"./data/004#biGRU_diff.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>urldata</th>\n",
       "      <th>pred</th>\n",
       "      <th>real</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>keyone=7976314481&amp;keytwo=foo%2520AND%25201427%...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>keyone=DF102861-F280-48A2-AAB8-8FD49E464E90&amp;ke...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>keyone=16-999.9+union+select+1%2Cconcat_ws%28u...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>keyone=1478158744072_249&amp;keytwo=1478073231783_...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>keyone=-1+UNION+ALL+SELECT+1%2C2%2C3&amp;keytwo=14...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>keyone=-2551%2527%2520WHERE%25205598%253D5598%...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>keyone=-1+union+select+1%2C2%2C3%2C4%2CUSER%28...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>keyone=1478670190391_179&amp;keytwo=1001-%5CN+unio...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>keyone=dc11bc8986524b6adbce87e84a81c2558523238...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>keyone=7971664867&amp;keytwo=VdB25Ot2q&amp;keythree=A+...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>keyone=7977282134&amp;keytwo=%25E5%25B7%25B2%25E7%...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>keyone=-1%2F1%2F%252A%252A%2Funion%2523--&amp;keyt...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>keyone=66874745%252C66874745&amp;keytwo=-999.9+UNI...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>keyone=7857382807&amp;keytwo=-1+union+select+1%2C2...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>keyone=a2b845a5cc309175b4a68c4346a35aa4&amp;keytwo...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>keyone=8f71e9216b8b8a0e7dcd21fdb8f389f98522110...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>keyone=7976172096&amp;keytwo=-1+OR+1%3D2&amp;keythree=2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>keyone=1478679546598_236&amp;keytwo=foo%2529%2520A...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>keyone=-4822%2527%2520OR%2520%25287582%253D907...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>keyone=11974609&amp;keytwo=-3740%2529%2520OR%2520N...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>keyone=%27+union+select+1%2C2%2Cuser%2Cpasswor...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>keyone=-68+union+select+1%2Cgroup_concat%28tab...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>keyone=1*1--&amp;keytwo=1477587171356_1557</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>keyone=-1+-+%28select+1%29+-+union+all+select+...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>keyone=http%253A%252F%252Fm.laiwang.com%252Fma...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>keyone=jsonp79&amp;keytwo=-1+or+1%3D%28select+user...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>keyone=1477407299127_296&amp;keytwo=7982588470&amp;key...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>keyone=527431399120&amp;keytwo=3&amp;keythree=1%2520AN...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>keyone=foo%2522%253B%2520SELECT%2520COUNT%2528...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>keyone=3d283a8b-85cf-4a9e-a270-4547cc554c4d&amp;ke...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>keyone=1478340974767_51&amp;keytwo=_LATIN7%27foo%2...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>keyone=1880+union+select+1%2C2%2C3%2C4+from+ne...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>keyone=yT6XJ6hD0q&amp;keytwo=-3523+union+select+1%...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>keyone=-7175%2527%2529%2529%2520UNION%2520ALL%...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>keyone=a806602f-309f-49ab-995b-355eae166b47&amp;ke...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              urldata  pred  real  label\n",
       "0   keyone=7976314481&keytwo=foo%2520AND%25201427%...     0     1      1\n",
       "1   keyone=DF102861-F280-48A2-AAB8-8FD49E464E90&ke...     1     0      0\n",
       "2   keyone=16-999.9+union+select+1%2Cconcat_ws%28u...     0     1      1\n",
       "3   keyone=1478158744072_249&keytwo=1478073231783_...     0     1      1\n",
       "4   keyone=-1+UNION+ALL+SELECT+1%2C2%2C3&keytwo=14...     0     1      1\n",
       "5   keyone=-2551%2527%2520WHERE%25205598%253D5598%...     0     1      1\n",
       "6   keyone=-1+union+select+1%2C2%2C3%2C4%2CUSER%28...     0     1      1\n",
       "7   keyone=1478670190391_179&keytwo=1001-%5CN+unio...     0     1      1\n",
       "8   keyone=dc11bc8986524b6adbce87e84a81c2558523238...     1     0      0\n",
       "9   keyone=7971664867&keytwo=VdB25Ot2q&keythree=A+...     0     1      1\n",
       "10  keyone=7977282134&keytwo=%25E5%25B7%25B2%25E7%...     1     0      0\n",
       "11  keyone=-1%2F1%2F%252A%252A%2Funion%2523--&keyt...     0     1      1\n",
       "12  keyone=66874745%252C66874745&keytwo=-999.9+UNI...     0     1      1\n",
       "13  keyone=7857382807&keytwo=-1+union+select+1%2C2...     0     1      1\n",
       "14  keyone=a2b845a5cc309175b4a68c4346a35aa4&keytwo...     1     0      0\n",
       "15  keyone=8f71e9216b8b8a0e7dcd21fdb8f389f98522110...     0     1      1\n",
       "16    keyone=7976172096&keytwo=-1+OR+1%3D2&keythree=2     0     1      1\n",
       "17  keyone=1478679546598_236&keytwo=foo%2529%2520A...     0     1      1\n",
       "18  keyone=-4822%2527%2520OR%2520%25287582%253D907...     0     1      1\n",
       "19  keyone=11974609&keytwo=-3740%2529%2520OR%2520N...     0     1      1\n",
       "20  keyone=%27+union+select+1%2C2%2Cuser%2Cpasswor...     0     1      1\n",
       "21  keyone=-68+union+select+1%2Cgroup_concat%28tab...     0     1      1\n",
       "22             keyone=1*1--&keytwo=1477587171356_1557     0     1      1\n",
       "23  keyone=-1+-+%28select+1%29+-+union+all+select+...     0     1      1\n",
       "24  keyone=http%253A%252F%252Fm.laiwang.com%252Fma...     1     0      0\n",
       "25  keyone=jsonp79&keytwo=-1+or+1%3D%28select+user...     0     1      1\n",
       "26  keyone=1477407299127_296&keytwo=7982588470&key...     0     1      1\n",
       "27  keyone=527431399120&keytwo=3&keythree=1%2520AN...     0     1      1\n",
       "28  keyone=foo%2522%253B%2520SELECT%2520COUNT%2528...     0     1      1\n",
       "29  keyone=3d283a8b-85cf-4a9e-a270-4547cc554c4d&ke...     0     1      1\n",
       "30  keyone=1478340974767_51&keytwo=_LATIN7%27foo%2...     0     1      1\n",
       "31  keyone=1880+union+select+1%2C2%2C3%2C4+from+ne...     0     1      1\n",
       "32  keyone=yT6XJ6hD0q&keytwo=-3523+union+select+1%...     0     1      1\n",
       "33  keyone=-7175%2527%2529%2529%2520UNION%2520ALL%...     0     1      1\n",
       "34  keyone=a806602f-309f-49ab-995b-355eae166b47&ke...     0     1      1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 200000 = 2000 * 100\n",
    "# n_hidden = 128 \n",
    "Step 100, Minibatch Loss= 0.725667, Training Accuracy= 0.49000\n",
    "Step 10000, Minibatch Loss= 0.473397, Training Accuracy= 0.78000\n",
    "Step 20000, Minibatch Loss= 0.276774, Training Accuracy= 0.94000\n",
    "Step 30000, Minibatch Loss= 0.073246, Training Accuracy= 0.98000\n",
    "Step 40000, Minibatch Loss= 0.115629, Training Accuracy= 0.97000\n",
    "Step 50000, Minibatch Loss= 0.058722, Training Accuracy= 0.99000\n",
    "Step 60000, Minibatch Loss= 0.095137, Training Accuracy= 0.98000\n",
    "Step 70000, Minibatch Loss= 0.107541, Training Accuracy= 0.97000\n",
    "Step 80000, Minibatch Loss= 0.039399, Training Accuracy= 0.99000\n",
    "Step 90000, Minibatch Loss= 0.131407, Training Accuracy= 0.96000\n",
    "Step 100000, Minibatch Loss= 0.081308, Training Accuracy= 0.98000\n",
    "Step 110000, Minibatch Loss= 0.087308, Training Accuracy= 0.98000\n",
    "Step 120000, Minibatch Loss= 0.090227, Training Accuracy= 0.98000\n",
    "Step 130000, Minibatch Loss= 0.125701, Training Accuracy= 0.97000\n",
    "Step 140000, Minibatch Loss= 0.165360, Training Accuracy= 0.94000\n",
    "Step 150000, Minibatch Loss= 0.139225, Training Accuracy= 0.96000\n",
    "Step 160000, Minibatch Loss= 0.132529, Training Accuracy= 0.96000\n",
    "Step 170000, Minibatch Loss= 0.178868, Training Accuracy= 0.95000\n",
    "Step 180000, Minibatch Loss= 0.092851, Training Accuracy= 0.98000\n",
    "Step 190000, Minibatch Loss= 0.086010, Training Accuracy= 0.98000\n",
    "Step 200000, Minibatch Loss= 0.173377, Training Accuracy= 0.96000\n",
    "Optimization Finished!\n",
    "Testing Accuracy: 0.96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
