{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import time\n",
    "import matplotlib\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from scipy import sparse\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_pd = pd.read_csv(\"./data/train.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 27500, 1: 2500})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(train_pd.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2500/3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 30000/30000 [00:00<00:00, 90943.34it/s]\n"
     ]
    }
   ],
   "source": [
    "word_list = []\n",
    "vocab_list = []\n",
    "for line in tqdm(train_pd.value):\n",
    "    word_list.append([w for w in line])\n",
    "    vocab_list.extend([w for w in line])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['%', '&', '*', '+', '-', '.', '0', '1', '2', '3', '4', '5', '6',\n",
       "       '7', '8', '9', '=', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I',\n",
       "       'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V',\n",
       "       'W', 'X', 'Y', 'Z', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h',\n",
       "       'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u',\n",
       "       'v', 'w', 'x', 'y', 'z'],\n",
       "      dtype='<U1')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = Counter(vocab_list)\n",
    "vocab = np.array(list(c.keys()))\n",
    "vocab.sort()\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
       "       68, 69], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = preprocessing.LabelEncoder()\n",
    "label_encoder.fit(vocab)\n",
    "label_encoder.classes_\n",
    "label_encoder.transform(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_labelencoder = [list(label_encoder.transform(w)) for w in word_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['k', 'e', 'y', 'o', 'n', 'e', '=', 'R', '8', '9', 'y', '0', 'w',\n",
       "       'd', 'I', 'l', 'T', 'H', 'A', '2', 'z', 'g', 'y', 'd', '1', 'C',\n",
       "       'C', '&', 'k', 'e', 'y', 't', 'w', 'o', '=', 'j', 'Q', 'u', 'e',\n",
       "       'r', 'y', '2', '1', '4', '0', '5', '6', '2', '4', '6', '5', '1',\n",
       "       '8', '8', '0', '3', '5', '2', '1', '6', '7', '_', '1', '4', '7',\n",
       "       '8', '1', '4', '5', '2', '3', '3', '2', '2', '2'],\n",
       "      dtype='<U1')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_labelencoder[0]\n",
    "label_encoder.inverse_transform(word_labelencoder[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30000,), (30000,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batch = np.array(word_labelencoder.copy())\n",
    "y_batch = np.array(train_pd.label.copy())\n",
    "# len(x), len(y)\n",
    "x_batch.shape, y_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_batch_size = [len(i) for i in x_batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11553"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_size = np.max(x_batch_size)\n",
    "max_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batch_size_pd = pd.DataFrame(x_batch_size, columns=['len'])\n",
    "x_batch_size_pd['label'] = train_pd.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>len</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>113.928533</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>173.427420</td>\n",
       "      <td>0.276390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>53.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>73.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>11553.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                len         label\n",
       "count  30000.000000  30000.000000\n",
       "mean     113.928533      0.083333\n",
       "std      173.427420      0.276390\n",
       "min       16.000000      0.000000\n",
       "25%       53.000000      0.000000\n",
       "50%       73.000000      0.000000\n",
       "75%      100.000000      0.000000\n",
       "max    11553.000000      1.000000"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batch_size_pd.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>len</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2500.00000</td>\n",
       "      <td>2500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>334.79320</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>193.83319</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>38.00000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>177.00000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>289.00000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>463.00000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1187.00000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              len   label\n",
       "count  2500.00000  2500.0\n",
       "mean    334.79320     1.0\n",
       "std     193.83319     0.0\n",
       "min      38.00000     1.0\n",
       "25%     177.00000     1.0\n",
       "50%     289.00000     1.0\n",
       "75%     463.00000     1.0\n",
       "max    1187.00000     1.0"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batch_size_pd[x_batch_size_pd.label == 1].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>len</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27500.000000</td>\n",
       "      <td>27500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>93.849927</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>156.713548</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>69.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>11553.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                len    label\n",
       "count  27500.000000  27500.0\n",
       "mean      93.849927      0.0\n",
       "std      156.713548      0.0\n",
       "min       16.000000      0.0\n",
       "25%       50.000000      0.0\n",
       "50%       69.000000      0.0\n",
       "75%       90.000000      0.0\n",
       "max    11553.000000      0.0"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batch_size_pd[x_batch_size_pd.label == 0].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 27500, 1: 2500})"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(x_batch_size_pd.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 27350, 1: 2497})"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batch_size_pd_100 = x_batch_size_pd[x_batch_size_pd.len <= 1000]\n",
    "Counter(x_batch_size_pd_100.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batch_size_pd = x_batch_size_pd.sort_values(['len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Must pass DataFrame with boolean values only",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-111-bfe2ea8bec03>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx_batch_size_pd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx_batch_size_pd\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1958\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1959\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1961\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_mi_columns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1962\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_frame\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2033\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2034\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_bool_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2035\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Must pass DataFrame with boolean values only'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2036\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2037\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Must pass DataFrame with boolean values only"
     ]
    }
   ],
   "source": [
    "x_batch_size_pd[x_batch_size_pd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x23ceb6885c0>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niIhICoWDiIik+P/BuPT86r8cjAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23ceb685dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_batch_size_pd.len.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 30000/30000 [00:20<00:00, 1482.67it/s]\n"
     ]
    }
   ],
   "source": [
    "x_batch_pad = []\n",
    "for x in tqdm(x_batch[:]):\n",
    "    list_test = list()\n",
    "    list_test = np.array([-1] * max_size)\n",
    "    list_test[:len(x)] = x\n",
    "    x_batch_pad.append(list_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 11553)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batch_pad = np.array(x_batch_pad)\n",
    "x_pos = x_batch_pad[y_batch==1]\n",
    "x_pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 11553)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_neg = x_batch_pad[y_batch==0]\n",
    "x_neg_index = np.array(range(len(x_neg)))\n",
    "x_neg_index = np.random.choice(x_neg_index, size=2500)\n",
    "x_neg = x_neg[x_neg_index]\n",
    "x_neg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2500, 11553), (2500, 11553))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pos.shape, x_neg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x_batch = np.append(x_pos, x_neg)\n",
    "x_batch = np.vstack([x_pos, x_neg])\n",
    "# x = np.array(list(x_pos).extend(x_neg))\n",
    "y_batch = np.concatenate([[1]*len(x_pos), [0]*len(x_neg)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[54, 48, 68, ..., -1, -1, -1],\n",
       "       [54, 48, 68, ..., -1, -1, -1],\n",
       "       [54, 48, 68, ..., -1, -1, -1],\n",
       "       ..., \n",
       "       [54, 48, 68, ..., -1, -1, -1],\n",
       "       [54, 48, 68, ..., -1, -1, -1],\n",
       "       [54, 48, 68, ..., -1, -1, -1]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index = np.arange(len(x_batch))\n",
    "np.random.shuffle(index)\n",
    "\n",
    "x_batch = x_batch[index]\n",
    "y_batch = y_batch[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 11553)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5000*0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11553,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11553,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batch[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Batcher():\n",
    "    def __init__(self, x, y, x_batch_size):\n",
    "        self.train_size = int(len(x)*0.8)\n",
    "        self.train_x = x[:self.train_size]\n",
    "        self.train_y = y[:self.train_size]\n",
    "        self.test_x = x[self.train_size:]\n",
    "        self.test_y = y[self.train_size:]\n",
    "        self.x_batch_size = np.array(x_batch_size)\n",
    "        self.start = 0\n",
    "    def next_batch(self, batch_size):\n",
    "        s_index = self.start\n",
    "        e_index = self.start + batch_size\n",
    "        if e_index >= self.train_size:\n",
    "            self.start = 0\n",
    "            s_index = self.start\n",
    "            e_index = self.start + batch_size\n",
    "        self.start = e_index\n",
    "        return self.train_x[s_index:e_index], self.train_y[s_index:e_index], self.x_batch_size[s_index:e_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "iteration over a 0-d array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-695dffddbef0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: iteration over a 0-d array"
     ]
    }
   ],
   "source": [
    "np.asarray(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#定义一些常量\n",
    "#图片大小，32 x 256\n",
    "OUTPUT_SHAPE = (len(vocab),256)\n",
    "\n",
    "#训练最大轮次\n",
    "num_epochs = 10000\n",
    "#LSTM\n",
    "num_hidden = 64\n",
    "num_layers = 1\n",
    "num_classes = 2\n",
    "\n",
    "# obj = gen_id_card()\n",
    "# num_classes = obj.len + 1 + 1  # 10位数字 + blank + ctc blank\n",
    "\n",
    "#初始化学习速率\n",
    "INITIAL_LEARNING_RATE = 1e-3\n",
    "DECAY_STEPS = 5000\n",
    "REPORT_STEPS = 100\n",
    "LEARNING_RATE_DECAY_FACTOR = 0.9  # The learning rate decay factor\n",
    "MOMENTUM = 0.9\n",
    "\n",
    "DIGITS='0123456789'\n",
    "BATCHES = 200\n",
    "BATCH_SIZE = 50\n",
    "TRAIN_SIZE = BATCHES * BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_train_model():\n",
    "    inputs = tf.placeholder(tf.float32, [None, 11553, OUTPUT_SHAPE[0]])\n",
    "    targets = tf.placeholder(tf.int32, [None])\n",
    "    seq_len = tf.placeholder(tf.int32, [None])\n",
    "    \n",
    "    with tf.name_scope(\"lstm\"):\n",
    "        # LSTM\n",
    "#         cell = tf.contrib.rnn.LSTMCell(num_hidden, state_is_tuple=True)\n",
    "#         stack = tf.contrib.rnn.MultiRNNCell([cell] * num_layers, state_is_tuple=True)\n",
    "#         outputs, _ = tf.nn.dynamic_rnn(cell, inputs, seq_len, dtype=tf.float32)\n",
    "        \n",
    "        cell = tf.nn.rnn_cell.GRUCell(num_units=num_hidden,)\n",
    "        stack = tf.nn.rnn_cell.MultiRNNCell([cell for _ in range(num_layers)],state_is_tuple=True)\n",
    "        outputs, _ = tf.nn.dynamic_rnn(cell, inputs, seq_len, dtype=tf.float32)\n",
    "\n",
    "        shape = tf.shape(inputs)\n",
    "        # [batch_size,256]\n",
    "        batch_s, max_timesteps = shape[0], shape[1]\n",
    "\n",
    "        # [batch_size*max_time_step,num_hidden]\n",
    "        outputs = tf.reshape(outputs, [-1, num_hidden])\n",
    "        W = tf.Variable(tf.truncated_normal([num_hidden,  num_classes], stddev=0.1), name=\"W\")\n",
    "        b = tf.Variable(tf.constant(0.0, shape=[num_classes]), name=\"b\")\n",
    "        # [batch_size*max_timesteps,num_classes]\n",
    "        logits = tf.matmul(outputs, W) + b\n",
    "        # [batch_size,max_timesteps,num_classes]\n",
    "        logits = tf.reshape(logits, [batch_s, -1, num_classes])\n",
    "        # 转置矩阵，第0和第1列互换位置=>[max_timesteps,batch_size,num_classes]\n",
    "        logits = tf.transpose(logits, (1, 0, 2))\n",
    "    \n",
    "    return logits, inputs, targets, seq_len, W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "learning_rate = tf.train.exponential_decay(INITIAL_LEARNING_RATE,\n",
    "                                                global_step,\n",
    "                                                DECAY_STEPS,\n",
    "                                                LEARNING_RATE_DECAY_FACTOR,\n",
    "                                                staircase=True)\n",
    "with tf.name_scope(\"rnn\"):\n",
    "    logits, inputs, targets, seq_len, W, b = get_train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'rnn/lstm/transpose_1:0' shape=(?, ?, 2) dtype=float32>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Tensor(\"rnn/gru_cell/gates/kernel:0\", shape=(134, 128), dtype=float32_ref) must be from the same graph as Tensor(\"CTCLoss:0\", shape=(?,), dtype=float32).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-83-dc77eadef132>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate,momentum=MOMENTUM).minimize(cost, global_step=global_step)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(self, loss, global_step, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, name, grad_loss)\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[0maggregation_method\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maggregation_method\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m         \u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 315\u001b[1;33m         grad_loss=grad_loss)\n\u001b[0m\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[0mvars_with_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mv\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mg\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\u001b[0m in \u001b[0;36mcompute_gradients\u001b[1;34m(self, loss, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, grad_loss)\u001b[0m\n\u001b[0;32m    384\u001b[0m         \u001b[0mgate_gradients\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgate_gradients\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGATE_OP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m         \u001b[0maggregation_method\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maggregation_method\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 386\u001b[1;33m         colocate_gradients_with_ops=colocate_gradients_with_ops)\n\u001b[0m\u001b[0;32m    387\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mgate_gradients\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGATE_GRAPH\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m       \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontrol_flow_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\u001b[0m in \u001b[0;36mgradients\u001b[1;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method)\u001b[0m\n\u001b[0;32m    422\u001b[0m     \u001b[0mgrad_ys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_AsList\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad_ys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 424\u001b[1;33m   \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"gradients\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mys\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mxs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mgrad_ys\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgrad_scope\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    425\u001b[0m     \u001b[0mys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_n_to_tensor_or_indexed_slices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"y\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m     xs = [x.handle if isinstance(x, resource_variable_ops.ResourceVariable)\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"generator didn't yield\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mname_scope\u001b[1;34m(name, default_name, values)\u001b[0m\n\u001b[0;32m   4356\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4357\u001b[0m     \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4358\u001b[1;33m   \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_graph_from_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4359\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mscope\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4360\u001b[0m     \u001b[1;32myield\u001b[0m \u001b[0mscope\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_get_graph_from_inputs\u001b[1;34m(op_input_list, graph)\u001b[0m\n\u001b[0;32m   4097\u001b[0m         \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4098\u001b[0m       \u001b[1;32melif\u001b[0m \u001b[0moriginal_graph_element\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4099\u001b[1;33m         \u001b[0m_assert_same_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginal_graph_element\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4100\u001b[0m       \u001b[1;32melif\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4101\u001b[0m         raise ValueError(\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_assert_same_graph\u001b[1;34m(original_item, item)\u001b[0m\n\u001b[0;32m   4036\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0moriginal_item\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4037\u001b[0m     raise ValueError(\n\u001b[1;32m-> 4038\u001b[1;33m         \"%s must be from the same graph as %s.\" % (item, original_item))\n\u001b[0m\u001b[0;32m   4039\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Tensor(\"rnn/gru_cell/gates/kernel:0\", shape=(134, 128), dtype=float32_ref) must be from the same graph as Tensor(\"CTCLoss:0\", shape=(?,), dtype=float32)."
     ]
    }
   ],
   "source": [
    "# tragets是一个稀疏矩阵\n",
    "# loss = tf.nn.ctc_loss(labels=targets,inputs=logits, sequence_length=seq_len)\n",
    "# cost = tf.reduce_mean(loss)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=targets, logits=logits))\n",
    "    \n",
    "#optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate,momentum=MOMENTUM).minimize(cost, global_step=global_step)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss,global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11553, 70), (50,))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs, train_targets, train_seq_len = sqli.next_batch(BATCH_SIZE)\n",
    "train_inputs[0].shape, train_seq_len.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_batch():\n",
    "#     train_inputs, train_targets, train_seq_len = get_next_batch(BATCH_SIZE)\n",
    "    train_inputs, train_targets, train_seq_len = sqli.next_batch(BATCH_SIZE)\n",
    "#     print(train_inputs, train_targets, train_seq_len)\n",
    "\n",
    "    feed = {inputs: train_inputs, targets: train_targets, seq_len: train_seq_len}\n",
    "\n",
    "    b_loss,b_targets, b_logits, b_seq_len,b_cost, steps, _ = session.run([loss, targets, logits, seq_len, cost, global_step, optimizer], feed)\n",
    "\n",
    "    print(b_cost, steps)\n",
    "    if steps > 0 and steps % REPORT_STEPS == 0:\n",
    "#         do_report()\n",
    "        save_path = saver.save(session, \"ocr.model\", global_step=steps)\n",
    "    return b_cost, steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# label_encoder.transform(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_batch = [np.eye(len(vocab))[item] for item in x_batch_pad]\n",
    "# x_batch = [np.eye(len(vocab))[item] for item in x_batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11553, 70)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch....... 0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape () for Tensor 'rnn/Placeholder_3:0', which has shape '(?, ?)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-6480377edafa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBATCHES\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m             \u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdo_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m             \u001b[0mtrain_cost\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0mseconds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-71-b1352532c76d>\u001b[0m in \u001b[0;36mdo_batch\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mfeed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtrain_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtrain_targets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtrain_seq_len\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mb_loss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb_targets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb_logits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb_seq_len\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb_cost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb_cost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    973\u001b[0m                 \u001b[1;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    974\u001b[0m                 \u001b[1;34m'which has shape %r'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 975\u001b[1;33m                 % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[0;32m    976\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    977\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Tensor %s may not be fed.'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot feed value of shape () for Tensor 'rnn/Placeholder_3:0', which has shape '(?, ?)'"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sqli = Batcher(x_batch,y_batch,x_batch_size)\n",
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "    saver = tf.train.Saver(tf.global_variables(), max_to_keep=100)\n",
    "    for curr_epoch in range(num_epochs):\n",
    "        print(\"Epoch.......\", curr_epoch)\n",
    "        train_cost = train_ler = 0\n",
    "        for batch in range(BATCHES):\n",
    "            start = time.time()\n",
    "            c, steps = do_batch()\n",
    "            train_cost += c * BATCH_SIZE\n",
    "            seconds = time.time() - start\n",
    "            print(\"Step:\", steps, \", batch seconds:\", seconds)\n",
    "            \n",
    "        train_cost /= TRAIN_SIZE\n",
    "            \n",
    "#         train_inputs, train_targets, train_seq_len = get_next_batch(BATCH_SIZE)\n",
    "#         train_inputs, train_targets, train_seq_len = sqli.next_batch(BATCH_SIZE)\n",
    "        print(train_inputs, train_targets, train_seq_len)\n",
    "        train_inputs = sqli.test_x\n",
    "        train_targets = sqli.test_y\n",
    "        train_seq_len = [len(w) for w in train_inputs]\n",
    "        val_feed = {inputs: train_inputs,\n",
    "                        targets: train_targets,\n",
    "                        seq_len: train_seq_len}\n",
    " \n",
    "        val_cost, val_ler, lr, steps = session.run([cost, acc, learning_rate, global_step], feed_dict=val_feed)\n",
    " \n",
    "        log = \"Epoch {}/{}, steps = {}, train_cost = {:.3f}, train_ler = {:.3f}, val_cost = {:.3f}, val_ler = {:.3f}, time = {:.3f}s, learning_rate = {}\"\n",
    "        print(log.format(curr_epoch + 1, num_epochs, steps, train_cost, train_ler, val_cost, val_ler, time.time() - start, lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    learning_rate = tf.train.exponential_decay(INITIAL_LEARNING_RATE,\n",
    "                                                global_step,\n",
    "                                                DECAY_STEPS,\n",
    "                                                LEARNING_RATE_DECAY_FACTOR,\n",
    "                                                staircase=True)\n",
    "    logits, inputs, targets, seq_len, W, b = get_train_model()\n",
    "    \n",
    "    # tragets是一个稀疏矩阵\n",
    "    loss = tf.nn.ctc_loss(labels=targets,inputs=logits, sequence_length=seq_len)\n",
    "    cost = tf.reduce_mean(loss)\n",
    "    \n",
    "    #optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate,momentum=MOMENTUM).minimize(cost, global_step=global_step)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss,global_step=global_step)\n",
    "    \n",
    "    #前面说的划分块之后找每块的类属概率分布，ctc_beam_search_decoder方法,是每次找最大的K个概率分布\n",
    "    #还有一种贪心策略是只找概率最大那个，也就是K=1的情况ctc_ greedy_decoder\n",
    "    decoded, log_prob = tf.nn.ctc_beam_search_decoder(logits, seq_len, merge_repeated=False)\n",
    "    \n",
    "    acc = tf.reduce_mean(tf.edit_distance(tf.cast(decoded[0], tf.int32), targets))\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    def report_accuracy(decoded_list, test_targets):\n",
    "        original_list = decode_sparse_tensor(test_targets)\n",
    "        detected_list = decode_sparse_tensor(decoded_list)\n",
    "        true_numer = 0\n",
    "        \n",
    "        if len(original_list) != len(detected_list):\n",
    "            print(\"len(original_list)\", len(original_list), \"len(detected_list)\", len(detected_list),\n",
    "                  \" test and detect length desn't match\")\n",
    "            return\n",
    "        print(\"T/F: original(length) <-------> detectcted(length)\")\n",
    "        for idx, number in enumerate(original_list):\n",
    "            detect_number = detected_list[idx]\n",
    "            hit = (number == detect_number)\n",
    "            print(hit, number, \"(\", len(number), \") <-------> \", detect_number, \"(\", len(detect_number), \")\")\n",
    "            if hit:\n",
    "                true_numer = true_numer + 1\n",
    "        print(\"Test Accuracy:\", true_numer * 1.0 / len(original_list))\n",
    "\n",
    "    def do_report():\n",
    "        test_inputs,test_targets,test_seq_len = get_next_batch(BATCH_SIZE)\n",
    "        test_feed = {inputs: test_inputs,\n",
    "                     targets: test_targets,\n",
    "                     seq_len: test_seq_len}\n",
    "        dd, log_probs, accuracy = session.run([decoded[0], log_prob, acc], test_feed)\n",
    "        report_accuracy(dd, test_targets)\n",
    " \n",
    "    def do_batch():\n",
    "        train_inputs, train_targets, train_seq_len = get_next_batch(BATCH_SIZE)\n",
    "        \n",
    "        feed = {inputs: train_inputs, targets: train_targets, seq_len: train_seq_len}\n",
    "        \n",
    "        b_loss,b_targets, b_logits, b_seq_len,b_cost, steps, _ = session.run([loss, targets, logits, seq_len, cost, global_step, optimizer], feed)\n",
    "        \n",
    "        print(b_cost, steps)\n",
    "        if steps > 0 and steps % REPORT_STEPS == 0:\n",
    "            do_report()\n",
    "            save_path = saver.save(session, \"ocr.model\", global_step=steps)\n",
    "        return b_cost, steps\n",
    "    \n",
    "    with tf.Session() as session:\n",
    "        session.run(init)\n",
    "        saver = tf.train.Saver(tf.global_variables(), max_to_keep=100)\n",
    "        for curr_epoch in xrange(num_epochs):\n",
    "            print(\"Epoch.......\", curr_epoch)\n",
    "            train_cost = train_ler = 0\n",
    "            for batch in xrange(BATCHES):\n",
    "                start = time.time()\n",
    "                c, steps = do_batch()\n",
    "                train_cost += c * BATCH_SIZE\n",
    "                seconds = time.time() - start\n",
    "                print(\"Step:\", steps, \", batch seconds:\", seconds)\n",
    "            \n",
    "            train_cost /= TRAIN_SIZE\n",
    "            \n",
    "            train_inputs, train_targets, train_seq_len = get_next_batch(BATCH_SIZE)\n",
    "            val_feed = {inputs: train_inputs,\n",
    "                        targets: train_targets,\n",
    "                        seq_len: train_seq_len}\n",
    " \n",
    "            val_cost, val_ler, lr, steps = session.run([cost, acc, learning_rate, global_step], feed_dict=val_feed)\n",
    " \n",
    "            log = \"Epoch {}/{}, steps = {}, train_cost = {:.3f}, train_ler = {:.3f}, val_cost = {:.3f}, val_ler = {:.3f}, time = {:.3f}s, learning_rate = {}\"\n",
    "            print(log.format(curr_epoch + 1, num_epochs, steps, train_cost, train_ler, val_cost, val_ler, time.time() - start, lr))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
